{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:10:28.611270900Z",
     "start_time": "2023-09-04T03:10:23.215957500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 20, 1])"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CNN_torch import SpatialAttention\n",
    "\n",
    "x = torch.normal(0, 1, (1, 1, 20, 1))\n",
    "sa = SpatialAttention()\n",
    "sa(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T05:13:10.979575400Z",
     "start_time": "2023-09-04T05:13:10.969463200Z"
    }
   },
   "id": "c6aa7f77adb9ea79"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 20, 3])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(0, 1, (1, 1, 20, 1))\n",
    "conv = torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 1), stride=1, padding=1, bias=False)\n",
    "conv(x).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T06:20:13.453179600Z",
     "start_time": "2023-09-04T06:20:13.447301200Z"
    }
   },
   "id": "3e38ce5cbd5bffe"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 12, 10, 1])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.normal(0, 1, (1, 8, 20, 3))\n",
    "b, c, h, w = x.shape\n",
    "split_s_h = h // 2\n",
    "split_s_w = w // 2\n",
    "xs = torch.cat(torch.split(x[:, :c // 4], split_s_h, dim=-2), dim=1).contiguous()\n",
    "xs = torch.cat(torch.split(xs, split_s_w, dim=-1),\n",
    "                           dim=1).contiguous()\n",
    "xs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T06:03:11.097388100Z",
     "start_time": "2023-09-04T06:03:11.088571400Z"
    }
   },
   "id": "708c622585389fe5"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 10, 3])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.split(x[:, :c // 4], split_s_h, dim=-2), dim=1).contiguous().shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T06:07:30.963694200Z",
     "start_time": "2023-09-04T06:07:30.954163600Z"
    }
   },
   "id": "6bbda3f325ffe617"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n",
      "torch.Size([1, 3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "N, C, H, W = (1, 3, 4, 4)\n",
    "x = torch.tensor([float(i) for i in range(1 * 3 * 4 * 4)]).reshape((1, 3, 4, 4))\n",
    "y = torch.fft.rfft2(x, norm='ortho')\n",
    "y_r, y_i = y.real, y.imag\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:12:43.197092100Z",
     "start_time": "2023-09-04T03:12:43.190941900Z"
    }
   },
   "id": "215aba94fabe9d99"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:10:50.671483200Z",
     "start_time": "2023-09-04T03:10:50.663768300Z"
    }
   },
   "id": "e4b0a608a7d4bfd8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 3, 4, 3]), torch.Size([1, 3, 4, 3]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.real.shape, y.imag.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:11:22.905765900Z",
     "start_time": "2023-09-04T03:11:22.901278300Z"
    }
   },
   "id": "d9057912782c065"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 4, 3])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T03:15:00.762317900Z",
     "start_time": "2023-09-04T03:15:00.757029100Z"
    }
   },
   "id": "24ac0a64af4cd80"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[[[0.8686, 0.8686, 0.8686, 0.8686],\n           [0.7808, 0.7808, 0.7808, 0.7808],\n           [0.6930, 0.6930, 0.6930, 0.6930],\n           [0.7808, 0.7808, 0.7808, 0.7808]],\n \n          [[0.8124, 0.8124, 0.8124, 0.8124],\n           [0.8124, 0.8124, 0.8124, 0.8124],\n           [0.8124, 0.8124, 0.8124, 0.8124],\n           [0.8124, 0.8124, 0.8124, 0.8124]],\n \n          [[0.8145, 0.8145, 0.8145, 0.8145],\n           [0.8145, 0.8145, 0.8145, 0.8145],\n           [0.8145, 0.8145, 0.8145, 0.8145],\n           [0.8145, 0.8145, 0.8145, 0.8145]],\n \n          [[0.8152, 0.8152, 0.8152, 0.8152],\n           [0.8152, 0.8152, 0.8152, 0.8152],\n           [0.8152, 0.8152, 0.8152, 0.8152],\n           [0.8152, 0.8152, 0.8152, 0.8152]],\n \n          [[0.8156, 0.8156, 0.8156, 0.8156],\n           [0.8156, 0.8156, 0.8156, 0.8156],\n           [0.8156, 0.8156, 0.8156, 0.8156],\n           [0.8156, 0.8156, 0.8156, 0.8156]],\n \n          [[0.8158, 0.8158, 0.8158, 0.8158],\n           [0.8158, 0.8158, 0.8158, 0.8158],\n           [0.8158, 0.8158, 0.8158, 0.8158],\n           [0.8158, 0.8158, 0.8158, 0.8158]]]], grad_fn=<FftC2RBackward0>),\n torch.Size([1, 6, 4, 4]))"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 迁移过来总感觉有些问题……\n",
    "def FU(x, out_channels):\n",
    "    batch_size, in_channels, height, width = x.shape\n",
    "    r_size = x.shape\n",
    "\n",
    "    conv = torch.nn.Conv2d(in_channels=in_channels * 2, out_channels=out_channels * 2, kernel_size=1, stride=1,\n",
    "                           padding=0, bias=False)\n",
    "    # init param\n",
    "    conv.weight.data = torch.tensor([float(i) for i in range(out_channels * 2 * in_channels * 2 * 1 * 1)]).reshape(\n",
    "        (out_channels * 2, in_channels * 2, 1, 1))\n",
    "\n",
    "    bn = torch.nn.BatchNorm2d(out_channels * 2)\n",
    "    relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "    y = torch.fft.rfft2(x, norm='ortho')\n",
    "    y_r, y_i = y.real, y.imag\n",
    "    y = torch.concat((y_r, y_i), dim=1)\n",
    "    y = conv(y)\n",
    "    y = bn(y)\n",
    "    y = relu(y)\n",
    "    y_r, y_i = torch.split(y, out_channels, dim=1)\n",
    "    y = torch.stack((y_r, y_i), dim=4)\n",
    "    y = torch.view_as_complex(y)\n",
    "    # y = y.view((batch_size, -1, 2,) + y.size()[2:]).permute(0, 1, 3, 4, 2).contiguous()\n",
    "    # z = torch.fft.irfft2(torch.view_as_complex(y), s=r_size[2:], norm='ortho')\n",
    "    z = torch.fft.irfft2(y, s=r_size[2:], norm='ortho')\n",
    "    print(z.shape)\n",
    "    return z\n",
    "\n",
    "\n",
    "z = FU(x, 6)\n",
    "z, z.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T04:52:07.774686800Z",
     "start_time": "2023-09-04T04:52:07.764785400Z"
    }
   },
   "id": "ca538f66b4c03ec6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
